{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac83a76f-427b-41eb-81d6-d10901c2abd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_jsonl_file(filepath):\n",
    "    \"\"\"\n",
    "    Reads the JSONL file and returns a list of dictionaries.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to the JSONL file.\n",
    "    \n",
    "    Returns:\n",
    "        data (list): A list of dictionaries containing the data from the JSONL file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18b10ace-4cf5-40dd-8ebd-e0b1fc36022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numerical_data(data):\n",
    "    \"\"\"\n",
    "    Extracts numerical fields from each entry in the data.\n",
    "    \n",
    "    Args:\n",
    "        data (list): A list of dictionaries containing data from the JSONL file.\n",
    "    \n",
    "    Returns:\n",
    "        numerical_data (dict): A dictionary containing lists of numerical values for each field.\n",
    "    \"\"\"\n",
    "    numerical_data = {\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1\": [],\n",
    "        \"onto_conf\": [],\n",
    "        \"rel_halluc\": [],\n",
    "        \"sub_halluc\": [],\n",
    "        \"obj_halluc\": []\n",
    "    }\n",
    "    \n",
    "    for entry in data:\n",
    "        numerical_data[\"precision\"].append(float(entry.get(\"precision\", 0.0)))\n",
    "        numerical_data[\"recall\"].append(float(entry.get(\"recall\", 0.0)))\n",
    "        numerical_data[\"f1\"].append(float(entry.get(\"f1\", 0.0)))\n",
    "        numerical_data[\"onto_conf\"].append(float(entry.get(\"onto_conf\", 0.0)))\n",
    "        numerical_data[\"rel_halluc\"].append(float(entry.get(\"rel_halluc\", 0.0)))\n",
    "        numerical_data[\"sub_halluc\"].append(float(entry.get(\"sub_halluc\", 0.0)))\n",
    "        numerical_data[\"obj_halluc\"].append(float(entry.get(\"obj_halluc\", 0.0)))\n",
    "    \n",
    "    return numerical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5df25422-c0b8-48f4-bce6-4aeb85a3d3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_averages(numerical_data):\n",
    "    \"\"\"\n",
    "    Calculates the average for each numerical field and returns them with prefixed keys.\n",
    "    \n",
    "    Args:\n",
    "        numerical_data (dict): A dictionary containing lists of numerical values for each field.\n",
    "    \n",
    "    Returns:\n",
    "        averages (dict): A dictionary containing the average values for each field, with \"avg_\" prefix.\n",
    "    \"\"\"\n",
    "    averages = {\n",
    "        \"avg_precision\": 0.0,\n",
    "        \"avg_recall\": 0.0,\n",
    "        \"avg_f1\": 0.0,\n",
    "        \"avg_onto_conf\": 0.0,\n",
    "        \"avg_rel_halluc\": 0.0,\n",
    "        \"avg_sub_halluc\": 0.0,\n",
    "        \"avg_obj_halluc\": 0.0\n",
    "    }\n",
    "    \n",
    "    for key, values in numerical_data.items():\n",
    "        avg_key = f\"avg_{key}\"\n",
    "        if values:\n",
    "            averages[avg_key] = sum(values) / len(values)\n",
    "    \n",
    "    return averages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52b90e21-bd2d-4be2-bcfc-27c8aa29fe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_jsonl(data, output_filepath):\n",
    "    \"\"\"\n",
    "    Saves a list of dictionaries to a JSONL file.\n",
    "    \n",
    "    Args:\n",
    "        data (list): A list of dictionaries containing average values for each file.\n",
    "        output_filepath (str): The path to the output JSONL file.\n",
    "    \"\"\"\n",
    "    with open(output_filepath, 'w', encoding='utf-8') as file:\n",
    "        for record in data:\n",
    "            json.dump(record, file)\n",
    "            file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "199e4fe2-0e07-446c-8e19-ff32179f3d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multiple_files(files, output_filepath):\n",
    "    \"\"\"\n",
    "    Processes multiple files to calculate and save their average statistics.\n",
    "    \n",
    "    Args:\n",
    "        files (list): A list of tuples where each tuple contains:\n",
    "                      - the filepath to the file\n",
    "                      - the ontology name (e.g., \"1_movie\", \"2_music\")\n",
    "        output_filepath (str): The path to the output JSONL file.\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    for filepath, ontology in files:\n",
    "        # Step 1: Read the JSONL file\n",
    "        data = read_jsonl_file(filepath)\n",
    "        \n",
    "        # Step 2: Extract numerical data\n",
    "        numerical_data = extract_numerical_data(data)\n",
    "        \n",
    "        # Step 3: Calculate averages for \"all_test_cases\"\n",
    "        averages_all = calculate_averages(numerical_data)\n",
    "        averages_all.update({\"onto\": ontology, \"type\": \"all_test_cases\"})\n",
    "        all_results.append(averages_all)\n",
    "        \n",
    "        # Step 4: (Optional) Calculate averages for \"selected_test_cases\"\n",
    "        # In this case, you might want to filter specific entries from data to\n",
    "        # create a subset of test cases. For now, this is an example without filtering.\n",
    "     #   averages_selected = calculate_averages(numerical_data)  # Assuming it's the same data structure\n",
    "      #  averages_selected.update({\"onto\": ontology, \"type\": \"selected_test_cases\"})\n",
    "    \n",
    "      #  all_results.append(averages_selected)\n",
    "    \n",
    "    # Step 5: Save all the results to a single JSONL file\n",
    "    save_to_jsonl(all_results, output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a7c3608-de29-46ee-bb3e-7991d703859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "files = [\n",
    "    ('Wikidata/Evaluation_Statistics/ont_1_movie_llm_stats.jsonl', '1_movie'),\n",
    "    ('Wikidata/Evaluation_Statistics/ont_2_music_llm_stats.jsonl', '2_music'),\n",
    "    ('Wikidata/Evaluation_Statistics/ont_3_sport_llm_stats.jsonl', '3_sport'),\n",
    "    ('Wikidata/Evaluation_Statistics/ont_5_military_llm_stats.jsonl', '5_military'),\n",
    "    ('Wikidata/Evaluation_Statistics/ont_6_computer_llm_stats.jsonl', '6_computer'),\n",
    "    ('Wikidata/Evaluation_Statistics/ont_7_space_llm_stats.jsonl', '7_space'),\n",
    "    ('Wikidata/Evaluation_Statistics/ont_8_politics_llm_stats.jsonl', '8_politics'),\n",
    "    ('Wikidata/Evaluation_Statistics/ont_9_nature_llm_stats.jsonl', '9_nature')\n",
    "]\n",
    "OUTPUT_FILEPATH = 'Wikidata/Avg_Eval_Statistics/combined_averages.jsonl'\n",
    "\n",
    "process_multiple_files(files, OUTPUT_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c2b27b-78b9-4ad0-b544-96acdd7ef12a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
